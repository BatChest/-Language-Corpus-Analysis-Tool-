{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Intra-sentential code switch frequency**\n",
        "\n",
        "We are analyzing conversations in files to see how often a child shifts between English and Cantonese within individual sentences."
      ],
      "metadata": {
        "id": "mn3PArdFZmd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHILDES Data we used\n",
        "# more specifically Eng/TimMixed folder\n",
        "# NOTE: folder_path need to be edited in order to run for yourself\n",
        "!wget https://git.talkbank.org/childes/data/Biling/YipMatthews.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c_auYvI_8mV0",
        "outputId": "623cab48-3360-4b2e-a4b4-eed55b37dacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-07 07:12:46--  https://git.talkbank.org/childes/data/Biling/YipMatthews.zip\n",
            "Resolving git.talkbank.org (git.talkbank.org)... 128.2.24.88\n",
            "Connecting to git.talkbank.org (git.talkbank.org)|128.2.24.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 319 [text/html]\n",
            "Saving to: ‘YipMatthews.zip.1’\n",
            "\n",
            "\rYipMatthews.zip.1     0%[                    ]       0  --.-KB/s               \rYipMatthews.zip.1   100%[===================>]     319  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-07 07:12:46 (125 MB/s) - ‘YipMatthews.zip.1’ saved [319/319]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installs the 'pylangacq' module\n",
        "# helps with reading .cha files (data was in this format)\n",
        "!pip install pylangacq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZQriU6hcqRuz",
        "outputId": "33724aa6-db8e-4b2e-884c-c27334b3c013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pylangacq in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: python-dateutil>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pylangacq) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from pylangacq) (2.32.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from tabulate[widechars]>=0.8.9->pylangacq) (0.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.0.0->pylangacq) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.0->pylangacq) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.0->pylangacq) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.0->pylangacq) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.0->pylangacq) (2024.8.30)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from tabulate[widechars]>=0.8.9->pylangacq) (0.2.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MAMQL34Fp23d"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "from pylangacq import read_chat\n",
        "\n",
        "def identify_language(word):\n",
        "  if re.match(r'^[a-zA-Z]+$', word):\n",
        "    return 'eng'\n",
        "  elif any(not char.isascii() for char in word):\n",
        "    return 'yue'\n",
        "  else:\n",
        "    # other: punctuation, numbers, etc\n",
        "    return 'other'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_utterance(utterance):\n",
        "    # Remove speaker tag and any annotations\n",
        "    utterance = utterance.split(':', 1)[-1].strip()\n",
        "    # removes the yue tag\n",
        "    if utterance.startswith('[- yue]'):\n",
        "      utterance = utterance[7:].strip()\n",
        "    elif utterance.startswith('[- eng]'):\n",
        "      return 'eng'\n",
        "\n",
        "    words = utterance.split()\n",
        "    languages = [identify_language(word) for word in words]\n",
        "    if 'eng' in languages and 'yue' in languages:\n",
        "      return 'intra-sentential'\n",
        "    elif 'eng' in languages and 'yue' not in languages:\n",
        "      return 'eng'\n",
        "    elif 'yue' in languages and 'eng' not in languages:\n",
        "      return 'yue'\n",
        "    else:\n",
        "      return 'other'"
      ],
      "metadata": {
        "id": "C09bzzPgsQNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_intra_sentential_code_switching(file_path):\n",
        "    corpus = read_chat(file_path)\n",
        "    utterances = corpus.utterances()\n",
        "\n",
        "    language_counts = {'intra-sentential': 0, 'eng': 0, 'yue': 0, 'other': 0}\n",
        "    # Changed 'mixed' to 'intra-sentential' to align with function logic\n",
        "\n",
        "    total_utterances = 0\n",
        "\n",
        "    for utterance in utterances:\n",
        "        if utterance.participant == 'CHI':\n",
        "            language, _, _, _ = analyze_utterance(utterance.tiers[utterance.participant])\n",
        "\n",
        "            # Check if the returned value is a tuple and extract the language label\n",
        "            if isinstance(language, tuple):\n",
        "                language = language[0]\n",
        "\n",
        "            # Map 'mixed' to 'intra-sentential' for consistency\n",
        "            if language == 'mixed':\n",
        "                language = 'intra-sentential'\n",
        "\n",
        "            language_counts[language] += 1\n",
        "            total_utterances += 1\n",
        "\n",
        "    return {\n",
        "        'total_utterances': total_utterances,\n",
        "        'intra_sentential_count': language_counts['intra-sentential'],\n",
        "        'intra_sentential_frequency': language_counts['intra-sentential'] / total_utterances if total_utterances > 0 else 0,\n",
        "        'language_distribution': {\n",
        "            lang: count / total_utterances\n",
        "            for lang, count in language_counts.items()\n",
        "        }\n",
        "    }\n",
        "\n",
        "def analyze_folder(folder_path):\n",
        "    results = []\n",
        "    cha_files = [f for f in os.listdir(folder_path) if f.endswith('.cha')]\n",
        "    cha_files.sort()\n",
        "\n",
        "    for i, file_name in enumerate(cha_files):\n",
        "        if i % 2 == 0:\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            file_results = analyze_intra_sentential_code_switching(file_path)\n",
        "            results.append((file_name, file_results))\n",
        "\n",
        "    return results\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/TimMixed'\n",
        "folder_results = analyze_folder(folder_path)\n",
        "\n",
        "for file_name, result in folder_results:\n",
        "    print(f\"Results for {file_name}:\")\n",
        "    print(f\"Total utterances: {result['total_utterances']}\")\n",
        "    print(f\"Intra-sentential count: {result['intra_sentential_count']} ({result['intra_sentential_frequency']:.2%})\")\n",
        "    print(f\"Code-Switching Frequency: {result['intra_sentential_frequency']:.2%}\")\n",
        "    print(\"Language distribution:\")\n",
        "    for lang, freq in result['language_distribution'].items():\n",
        "        print(f\"  {lang}: {freq:.2%}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbmXaX23T6-F",
        "outputId": "c7a66389-fa48-477f-bb5a-d6f49cf1b2ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 010520.cha:\n",
            "Total utterances: 123\n",
            "Intra-sentential count: 0 (0.00%)\n",
            "Code-Switching Frequency: 0.00%\n",
            "Language distribution:\n",
            "  intra-sentential: 0.00%\n",
            "  eng: 41.46%\n",
            "  yue: 31.71%\n",
            "  other: 26.83%\n",
            "\n",
            "Results for 010624.cha:\n",
            "Total utterances: 132\n",
            "Intra-sentential count: 0 (0.00%)\n",
            "Code-Switching Frequency: 0.00%\n",
            "Language distribution:\n",
            "  intra-sentential: 0.00%\n",
            "  eng: 54.55%\n",
            "  yue: 35.61%\n",
            "  other: 9.85%\n",
            "\n",
            "Results for 010723.cha:\n",
            "Total utterances: 114\n",
            "Intra-sentential count: 0 (0.00%)\n",
            "Code-Switching Frequency: 0.00%\n",
            "Language distribution:\n",
            "  intra-sentential: 0.00%\n",
            "  eng: 65.79%\n",
            "  yue: 24.56%\n",
            "  other: 9.65%\n",
            "\n",
            "Results for 010826.cha:\n",
            "Total utterances: 273\n",
            "Intra-sentential count: 1 (0.37%)\n",
            "Code-Switching Frequency: 0.37%\n",
            "Language distribution:\n",
            "  intra-sentential: 0.37%\n",
            "  eng: 43.22%\n",
            "  yue: 48.72%\n",
            "  other: 7.69%\n",
            "\n",
            "Results for 011002.cha:\n",
            "Total utterances: 204\n",
            "Intra-sentential count: 3 (1.47%)\n",
            "Code-Switching Frequency: 1.47%\n",
            "Language distribution:\n",
            "  intra-sentential: 1.47%\n",
            "  eng: 42.65%\n",
            "  yue: 45.10%\n",
            "  other: 10.78%\n",
            "\n",
            "Results for 011121.cha:\n",
            "Total utterances: 350\n",
            "Intra-sentential count: 3 (0.86%)\n",
            "Code-Switching Frequency: 0.86%\n",
            "Language distribution:\n",
            "  intra-sentential: 0.86%\n",
            "  eng: 56.57%\n",
            "  yue: 37.14%\n",
            "  other: 5.43%\n",
            "\n",
            "Results for 020108.cha:\n",
            "Total utterances: 377\n",
            "Intra-sentential count: 9 (2.39%)\n",
            "Code-Switching Frequency: 2.39%\n",
            "Language distribution:\n",
            "  intra-sentential: 2.39%\n",
            "  eng: 40.85%\n",
            "  yue: 44.56%\n",
            "  other: 12.20%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results**:\n",
        "\n",
        "total_utterances: total number of utterances analyzed in the file\n",
        "\n",
        "intra_sentential_count: number of utterances that contain sentential code-switching (mix of English and Cantonese)\n",
        "\n",
        "intra_sentential_frequency: frequency of intra-sentential code-switching\n",
        "\n",
        "language_distribution:\n",
        "Shows the proportion of utterances in each category:\n",
        "\n",
        "'intra-sentential': same as intra_sentential_frequency\n",
        "\n",
        "'eng': Proportion of utterances that are purely in English\n",
        "\n",
        "'yue': Proportion of utterances that are purely in Cantonese\n",
        "\n",
        "'other': Proportion of utterances that don't fit the two languages\n"
      ],
      "metadata": {
        "id": "Pi6x4ZG4YtHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grammatical Structure of Code Switching**\n",
        "\n",
        "Here, we examine the components of speech of English words used in mixed-language sentences. In addition to determining average sentence lengths, the frequency of mixed-langage sentences, and the distribution of various language kinds."
      ],
      "metadata": {
        "id": "_pTPuANVa89k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download the necessary NLTK data package\n",
        "# helps with part of speech tagging\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "def identify_language(word):\n",
        "  if re.match(r'^[a-zA-Z]+$', word):\n",
        "    return 'eng'\n",
        "  elif any(not char.isascii() for char in word):\n",
        "    return 'yue'\n",
        "  else:\n",
        "    # other: punctuation, numbers, etc\n",
        "    return 'other'"
      ],
      "metadata": {
        "id": "pOKgTPf7a1QK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "2be67235-eb01-4846-ca9e-c22c3e64da84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_pos(word):\n",
        "  pos = pos_tag([word])[0][1]\n",
        "  if pos.startswith('VB'):\n",
        "    return 'verb'\n",
        "  elif pos.startswith('NN'):\n",
        "    return 'noun'\n",
        "  elif pos.startswith('JJ'):\n",
        "    return 'adjective'\n",
        "  elif pos.startswith('RB'):\n",
        "    return 'adverb'\n",
        "  else:\n",
        "    return 'other'"
      ],
      "metadata": {
        "id": "oTPDHXWzbjo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_utterance(utterance):\n",
        "    utterance = utterance.split(':', 1)[-1].strip()\n",
        "    if utterance.startswith('[- yue]'):\n",
        "        utterance = utterance[7:].strip()\n",
        "    elif utterance.startswith('[- eng]'):\n",
        "        return 'eng', [], 0, 0\n",
        "\n",
        "    words = utterance.split()\n",
        "    languages = [identify_language(word) for word in words]\n",
        "    eng_words = [word for word, lang in zip(words, languages) if lang == 'eng']\n",
        "    eng_pos = [analyze_pos(word) for word in eng_words]\n",
        "\n",
        "    if 'eng' in languages and 'yue' in languages:\n",
        "        return 'mixed', eng_pos, len(words), len(eng_words)\n",
        "    elif 'eng' in languages:\n",
        "        return 'eng', eng_pos, len(words), len(eng_words)\n",
        "    elif 'yue' in languages:\n",
        "        return 'yue', eng_pos, len(words), len(eng_words)\n",
        "    else:\n",
        "        return 'other', eng_pos, len(words), len(eng_words)"
      ],
      "metadata": {
        "id": "WLwEJpLxbxYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_file(file_path):\n",
        "    corpus = read_chat(file_path)\n",
        "    utterances = corpus.utterances()\n",
        "\n",
        "    language_counts = {'mixed': 0, 'eng': 0, 'yue': 0, 'other': 0}\n",
        "    pos_counts = {'noun': 0, 'verb': 0, 'adjective': 0, 'adverb': 0, 'other': 0}\n",
        "    total_words = 0\n",
        "    total_eng_words = 0\n",
        "    total_sentences = 0\n",
        "    mixed_sentences = 0\n",
        "    mixed_words = 0\n",
        "\n",
        "    for utterance in utterances:\n",
        "        if utterance.participant == 'CHI':\n",
        "            language, eng_pos, sent_len, eng_len = analyze_utterance(utterance.tiers[utterance.participant])\n",
        "            language_counts[language] += 1\n",
        "            total_sentences += 1\n",
        "            total_words += sent_len\n",
        "            total_eng_words += eng_len\n",
        "            if language == 'mixed':\n",
        "                mixed_sentences += 1\n",
        "                mixed_words += sent_len\n",
        "                for pos in eng_pos:\n",
        "                    pos_counts[pos] += 1\n",
        "\n",
        "    # caculate the averages\n",
        "    avg_sent_len = total_words / total_sentences if total_sentences > 0 else 0\n",
        "    avg_mixed_sent_len = mixed_words / mixed_sentences if mixed_sentences > 0 else 0\n",
        "    avg_eng_words = total_eng_words / total_sentences if total_sentences > 0 else 0\n",
        "\n",
        "\n",
        "    return {\n",
        "        'file_name': os.path.basename(file_path),\n",
        "        'total_sentences': total_sentences,\n",
        "        'mixed_sentence_count': language_counts['mixed'],\n",
        "        'mixed_sentence_frequency': language_counts['mixed'] / total_sentences if total_sentences > 0 else 0,\n",
        "        'avg_sentence_length': avg_sent_len,\n",
        "        'avg_mixed_sentence_length': avg_mixed_sent_len,\n",
        "        'avg_english_words_per_sentence': avg_eng_words,\n",
        "        'pos_distribution': {pos: count / sum(pos_counts.values()) for pos, count in pos_counts.items() if sum(pos_counts.values()) > 0},\n",
        "        'language_distribution': {lang: count / total_sentences for lang, count in language_counts.items()}\n",
        "    }"
      ],
      "metadata": {
        "id": "wR0D4XqVMzyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_folder(folder_path):\n",
        "    results = []\n",
        "    cha_files = [f for f in os.listdir(folder_path) if f.endswith('.cha')]\n",
        "    cha_files.sort()\n",
        "\n",
        "    for i, file_name in enumerate(cha_files):\n",
        "        if i % 2 == 0:\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            file_results = analyze_file(file_path)\n",
        "            results.append((file_name, file_results))\n",
        "\n",
        "    return results\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/TimMixed'\n",
        "folder_results = analyze_folder(folder_path)\n",
        "\n",
        "for file_name, result in folder_results:\n",
        "    print(f\"Results for {file_name}:\")\n",
        "    print(f\"Total sentences: {result['total_sentences']}\")\n",
        "    print(f\"Mixed sentences: {result['mixed_sentence_count']} ({result['mixed_sentence_frequency']:.2%})\")\n",
        "    print(f\"Average sentence length: {result['avg_sentence_length']:.2f}\")\n",
        "    print(f\"Average mixed sentence length: {result['avg_mixed_sentence_length']:.2f}\")\n",
        "    print(f\"Average English words per sentence: {result['avg_english_words_per_sentence']:.2f}\")\n",
        "    print(\"POS distribution of English words in mixed sentences:\")\n",
        "    for pos, freq in result['pos_distribution'].items():\n",
        "        print(f\"  {pos}: {freq:.2%}\")\n",
        "    print(\"Language distribution:\")\n",
        "    for lang, freq in result['language_distribution'].items():\n",
        "        print(f\"  {lang}: {freq:.2%}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwHhhLsPPDqp",
        "outputId": "f3177d13-ae32-4a4e-b49b-3a70e670b8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 010520.cha:\n",
            "Total sentences: 123\n",
            "Mixed sentences: 0 (0.00%)\n",
            "Average sentence length: 2.33\n",
            "Average mixed sentence length: 0.00\n",
            "Average English words per sentence: 0.44\n",
            "POS distribution of English words in mixed sentences:\n",
            "Language distribution:\n",
            "  mixed: 0.00%\n",
            "  eng: 41.46%\n",
            "  yue: 31.71%\n",
            "  other: 26.83%\n",
            "\n",
            "Results for 010624.cha:\n",
            "Total sentences: 132\n",
            "Mixed sentences: 0 (0.00%)\n",
            "Average sentence length: 2.36\n",
            "Average mixed sentence length: 0.00\n",
            "Average English words per sentence: 0.61\n",
            "POS distribution of English words in mixed sentences:\n",
            "Language distribution:\n",
            "  mixed: 0.00%\n",
            "  eng: 54.55%\n",
            "  yue: 35.61%\n",
            "  other: 9.85%\n",
            "\n",
            "Results for 010723.cha:\n",
            "Total sentences: 114\n",
            "Mixed sentences: 0 (0.00%)\n",
            "Average sentence length: 2.21\n",
            "Average mixed sentence length: 0.00\n",
            "Average English words per sentence: 0.69\n",
            "POS distribution of English words in mixed sentences:\n",
            "Language distribution:\n",
            "  mixed: 0.00%\n",
            "  eng: 65.79%\n",
            "  yue: 24.56%\n",
            "  other: 9.65%\n",
            "\n",
            "Results for 010826.cha:\n",
            "Total sentences: 273\n",
            "Mixed sentences: 1 (0.37%)\n",
            "Average sentence length: 2.61\n",
            "Average mixed sentence length: 3.00\n",
            "Average English words per sentence: 0.47\n",
            "POS distribution of English words in mixed sentences:\n",
            "  noun: 100.00%\n",
            "  verb: 0.00%\n",
            "  adjective: 0.00%\n",
            "  adverb: 0.00%\n",
            "  other: 0.00%\n",
            "Language distribution:\n",
            "  mixed: 0.37%\n",
            "  eng: 43.22%\n",
            "  yue: 48.72%\n",
            "  other: 7.69%\n",
            "\n",
            "Results for 011002.cha:\n",
            "Total sentences: 204\n",
            "Mixed sentences: 3 (1.47%)\n",
            "Average sentence length: 3.01\n",
            "Average mixed sentence length: 3.00\n",
            "Average English words per sentence: 0.49\n",
            "POS distribution of English words in mixed sentences:\n",
            "  noun: 100.00%\n",
            "  verb: 0.00%\n",
            "  adjective: 0.00%\n",
            "  adverb: 0.00%\n",
            "  other: 0.00%\n",
            "Language distribution:\n",
            "  mixed: 1.47%\n",
            "  eng: 42.65%\n",
            "  yue: 45.10%\n",
            "  other: 10.78%\n",
            "\n",
            "Results for 011121.cha:\n",
            "Total sentences: 350\n",
            "Mixed sentences: 3 (0.86%)\n",
            "Average sentence length: 3.13\n",
            "Average mixed sentence length: 3.00\n",
            "Average English words per sentence: 0.86\n",
            "POS distribution of English words in mixed sentences:\n",
            "  noun: 100.00%\n",
            "  verb: 0.00%\n",
            "  adjective: 0.00%\n",
            "  adverb: 0.00%\n",
            "  other: 0.00%\n",
            "Language distribution:\n",
            "  mixed: 0.86%\n",
            "  eng: 56.57%\n",
            "  yue: 37.14%\n",
            "  other: 5.43%\n",
            "\n",
            "Results for 020108.cha:\n",
            "Total sentences: 377\n",
            "Mixed sentences: 9 (2.39%)\n",
            "Average sentence length: 3.21\n",
            "Average mixed sentence length: 3.44\n",
            "Average English words per sentence: 0.73\n",
            "POS distribution of English words in mixed sentences:\n",
            "  noun: 88.89%\n",
            "  verb: 11.11%\n",
            "  adjective: 0.00%\n",
            "  adverb: 0.00%\n",
            "  other: 0.00%\n",
            "Language distribution:\n",
            "  mixed: 2.39%\n",
            "  eng: 40.85%\n",
            "  yue: 44.56%\n",
            "  other: 12.20%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results:\n",
        "\n",
        "Total sentences: Total number of utterances analyzed in the file.\n",
        "\n",
        "Mixed sentences: Number and percentage of utterances that contain both English and Cantonese\n",
        "\n",
        "Average sentence length: The mean number of words per utterance across all utterances.\n",
        "\n",
        "Average mixed sentence length: The mean number of words in utterances that contain both English and Cantonese.\n",
        "\n",
        "Average English words per sentence: The mean number of English words across all utterances.\n",
        "\n",
        "POS distribution of English words in mixed sentences:\n",
        "This shows the distribution of parts of speech for English words in mixed utterances.\n",
        "\n",
        "noun: Percentage of English words that are nouns.\n",
        "\n",
        "verb: Percentage of English words that are verbs.\n",
        "\n",
        "adjective: Percentage of English words that are adjectives.\n",
        "\n",
        "adverb: Percentage of English words that are adverbs.\n",
        "\n",
        "other: Percentage of English words that are other parts of speech or unclassified.\n",
        "\n",
        "Language distribution:\n",
        "This shows the proportion of utterances in each language category.\n",
        "\n",
        "mixed: Percentage of utterances containing both English and Cantonese.\n",
        "\n",
        "eng: Percentage of utterances that are purely in English.\n",
        "\n",
        "yue: Percentage of utterances that are purely in Cantonese.\n",
        "\n",
        "other: Percentage of utterances that don't fit into the above categories (might include other languages, non-linguistic vocalizations, etc.)."
      ],
      "metadata": {
        "id": "umOGoEaRVboE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparing Files**\n",
        "\n",
        "Here, we compare the analysis findings from multiple files. It arranges the files and compares key metrics between them. The metrics employed are the frequency of code-switching, average sentence length, average mixed sentence length, and the average number of English words per sentence."
      ],
      "metadata": {
        "id": "VAL08qIbb9hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_files(results):\n",
        "  # Sort results by file name\n",
        "  sorted_results = sorted(results, key=lambda x: x[0])\n",
        "\n",
        "  print(\"File Comparison:\")\n",
        "  for i, (file_name, result) in enumerate(sorted_results):\n",
        "        print(f\"\\nFile: {file_name}\")\n",
        "        print(f\"Code-switching frequency: {result['mixed_sentence_frequency']:.2%}\")\n",
        "        print(f\"Average sentence length: {result['avg_sentence_length']:.2f}\")\n",
        "        print(f\"Average mixed sentence length: {result['avg_mixed_sentence_length']:.2f}\")\n",
        "        print(f\"Average English words per sentence: {result['avg_english_words_per_sentence']:.2f}\")\n",
        "\n",
        "        if i > 0:\n",
        "            prev_result = sorted_results[i-1][1]\n",
        "            print(\"\\nChanges from previous file:\")\n",
        "            print(f\"Code-switching frequency change: {result['mixed_sentence_frequency'] - prev_result['mixed_sentence_frequency']:.2%}\")\n",
        "            print(f\"Average sentence length change: {result['avg_sentence_length'] - prev_result['avg_sentence_length']:.2f}\")\n",
        "            print(f\"Average mixed sentence length change: {result['avg_mixed_sentence_length'] - prev_result['avg_mixed_sentence_length']:.2f}\")\n",
        "            print(f\"Average English words per sentence change: {result['avg_english_words_per_sentence'] - prev_result['avg_english_words_per_sentence']:.2f}\")\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/TimMixed'\n",
        "folder_results = analyze_folder(folder_path)\n",
        "\n",
        "compare_files(folder_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQDu6MK_W62V",
        "outputId": "5c67b427-17ce-4a95-8b02-de048038a4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Comparison:\n",
            "\n",
            "File: 010520.cha\n",
            "Code-switching frequency: 3.88%\n",
            "Average sentence length: 3.46\n",
            "Average mixed sentence length: 6.58\n",
            "Average English words per sentence: 1.07\n",
            "\n",
            "File: 010624.cha\n",
            "Code-switching frequency: 8.82%\n",
            "Average sentence length: 3.61\n",
            "Average mixed sentence length: 5.94\n",
            "Average English words per sentence: 0.51\n",
            "\n",
            "Changes from previous file:\n",
            "Code-switching frequency change: 4.94%\n",
            "Average sentence length change: 0.15\n",
            "Average mixed sentence length change: -0.64\n",
            "Average English words per sentence change: -0.57\n",
            "\n",
            "File: 010723.cha\n",
            "Code-switching frequency: 5.71%\n",
            "Average sentence length: 3.33\n",
            "Average mixed sentence length: 6.08\n",
            "Average English words per sentence: 0.84\n",
            "\n",
            "Changes from previous file:\n",
            "Code-switching frequency change: -3.11%\n",
            "Average sentence length change: -0.28\n",
            "Average mixed sentence length change: 0.14\n",
            "Average English words per sentence change: 0.33\n",
            "\n",
            "File: 010826.cha\n",
            "Code-switching frequency: 3.01%\n",
            "Average sentence length: 3.34\n",
            "Average mixed sentence length: 5.64\n",
            "Average English words per sentence: 0.52\n",
            "\n",
            "Changes from previous file:\n",
            "Code-switching frequency change: -2.71%\n",
            "Average sentence length change: 0.01\n",
            "Average mixed sentence length change: -0.44\n",
            "Average English words per sentence change: -0.31\n",
            "\n",
            "File: 011002.cha\n",
            "Code-switching frequency: 3.70%\n",
            "Average sentence length: 3.62\n",
            "Average mixed sentence length: 5.35\n",
            "Average English words per sentence: 0.55\n",
            "\n",
            "Changes from previous file:\n",
            "Code-switching frequency change: 0.70%\n",
            "Average sentence length change: 0.28\n",
            "Average mixed sentence length change: -0.28\n",
            "Average English words per sentence change: 0.03\n",
            "\n",
            "File: 011121.cha\n",
            "Code-switching frequency: 1.87%\n",
            "Average sentence length: 3.35\n",
            "Average mixed sentence length: 4.89\n",
            "Average English words per sentence: 0.88\n",
            "\n",
            "Changes from previous file:\n",
            "Code-switching frequency change: -1.84%\n",
            "Average sentence length change: -0.26\n",
            "Average mixed sentence length change: -0.46\n",
            "Average English words per sentence change: 0.32\n",
            "\n",
            "File: 020108.cha\n",
            "Code-switching frequency: 3.39%\n",
            "Average sentence length: 3.60\n",
            "Average mixed sentence length: 5.28\n",
            "Average English words per sentence: 0.93\n",
            "\n",
            "Changes from previous file:\n",
            "Code-switching frequency change: 1.52%\n",
            "Average sentence length change: 0.25\n",
            "Average mixed sentence length change: 0.39\n",
            "Average English words per sentence change: 0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results:\n",
        "\n",
        "Code-switching frequency change: Percentage change in how oftern the child mixes English and Cantonese within sentences\n",
        "\n",
        "Average sentence length change: Change in average number of words per sentence, indicating overall sentence complexity\n",
        "\n",
        "Average mixed sentence length change: Shows how the length of sentences containing both languages has changed.\n",
        "\n",
        "Average English words per sentence change: Represents the shift in the average number of English words used in each sentence."
      ],
      "metadata": {
        "id": "fpavPxfpYdEI"
      }
    }
  ]
}